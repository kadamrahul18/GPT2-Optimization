# GPT-2-optimization
Optimizing GPT-2 Training and Inference: Hybrid Parallelism with Megatron-LM, FlashAttention, and Quantization
